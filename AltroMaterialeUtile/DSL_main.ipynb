{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "# Feature selection\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import hilbert\n",
    "from math import log10\n",
    "import parselmouth\n",
    "from maad import sound as suono\n",
    "from maad import features as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvTotale = pd.read_csv('./data/development.csv', header=0, index_col=0).drop(columns=['sampling_rate'])\n",
    "csvTotale['gender'] = csvTotale['gender'].map(lambda x: 0 if x=='male' else 1)\n",
    "csvTotale['tempo'] = csvTotale['tempo'].map(lambda x: float(x[1:-1]))\n",
    "csvTotale['path'] = csvTotale['path'].map(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvEval = pd.read_csv('./data/evaluation.csv', header=0, index_col=0).drop(columns=['sampling_rate'])\n",
    "csvEval['gender'] = csvEval['gender'].map(lambda x: 0 if x=='male' else 1)\n",
    "csvEval['tempo'] = csvEval['tempo'].map(lambda x: float(x[1:-1]))\n",
    "csvEval['path'] = csvEval['path'].map(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cross_val_score(HistGradientBoostingRegressor(categorical_features=csvTotale.drop(columns=['path', 'age']).dtypes == 'object'), \n",
    "                csvTotale.drop(columns=['path', 'age']), \n",
    "                csvTotale['age'], cv=10, scoring='neg_root_mean_squared_error').mean(),\n",
    " cross_val_score(make_pipeline(StandardScaler(), MLPRegressor(max_iter=1000)), \n",
    "                csvTotale.drop(columns=['path', 'age', 'ethnicity']), \n",
    "                csvTotale['age'], cv=10, scoring='neg_root_mean_squared_error').mean())\n",
    "\n",
    "# BASELINE = -7.24, -8.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioDevelopment = {file: librosa.load('./data/audios_development/'+file, sr=22050)[0] for file in csvTotale['path']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION TO EXTRACT FURTHER FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMFCC(audio):\n",
    "    numFcc = 35\n",
    "    return pd.Series(librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=numFcc).mean(axis=1), index=[f'mfcc{i}' for i in range(numFcc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpectralEnergy(audio):\n",
    "    S = librosa.stft(audio)\n",
    "    freqs = librosa.fft_frequencies(sr=22050)\n",
    "    return pd.Series([np.sum(np.abs(S[(freqs >= 250) & (freqs <= 650)])**2), np.sum(np.abs(S[(freqs >= 1000) & (freqs <= 8000)])**2)],\n",
    "                        index=['spectralEnergy250-650', 'spectralEnergy1000-8000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeParselMouthStats(audio):\n",
    "    sound = parselmouth.Sound(audio)\n",
    "    pitch = sound.to_pitch()\n",
    "    info = str(pitch.info()).split('\\n')\n",
    "    return pd.Series([pitch.count_voiced_frames(), pitch.get_mean_absolute_slope(), pitch.xmax-pitch.xmin, \n",
    "                      pitch.n_frames, *[float(info[15+i].split('=')[2].lstrip().split(' =')[0].split()[0]) for i in range(0, 5)],\n",
    "                      *[float(info[21+i].split('=')[2].lstrip().split(' =')[0].split()[0]) for i in range(0, 3)]],\n",
    "                     index=['nVoicedFrames', 'meanAbsoluteSlope', 'duration', 'nFrames', \n",
    "                            'q10', 'q16', 'q50', 'q84', 'q90', '84-median', 'median-16', '90-10']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMath(audio):\n",
    "    return pd.Series([skew(audio), kurtosis(audio), np.mean(np.abs(hilbert(audio))), np.mean(np.abs(np.fft.fft(audio)))],\n",
    "                     index=['skew', 'kurtosis', 'hilbertMean', 'fftMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computSNR(audio):\n",
    "    return pd.Series([suono.temporal_snr(audio)[-1]], index=['temporalSNR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTemporalMedia(audio):\n",
    "    return pd.Series([ft.temporal_median(audio)], index=['temporalMedian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllFeatures(audio):\n",
    "    return pd.Series(ft.all_temporal_features(audio, fs=22050, nperseg=256).values[0],\n",
    "                     index=['sm', 'sv', 'ss', 'sk', 'Time 5%', \"Time 25%\", \"Time 50%\", \"Time 75%\", \"Time 95%  \", \n",
    "                            \"zcr\", \"duration_5\", \"duration_90\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePeakFrequency(audio):\n",
    "    return pd.Series(ft.peak_frequency(audio, fs=22050, nperseg=256, amp=True), index=['peakFrequency', 'peakFrequencyAmp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEntropy(audio):\n",
    "    return pd.Series(ft.temporal_entropy(audio), index=['entropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO BUENO JUST NOISE\n",
    "def computeMaadStats(audio):\n",
    "    Sxx_power, tn, fn, _ = suono.spectrogram(audio, 22050)      \n",
    "    return pd.Series([ft.number_of_peaks(Sxx_power, fn=fn, nperseg=256), \n",
    "                      ft.bioacoustics_index(Sxx_power, fn=fn, flim=(100, 3000)),\n",
    "                      ft.acoustic_diversity_index(Sxx_power, fn=fn, fmin=80, fmax=3000),\n",
    "                      ft.acoustic_eveness_index(Sxx_power, fn=fn, fmin=80, fmax=3000),\n",
    "                      ],\n",
    "                    index=['nPeaks', 'bioIndex', 'acousticDiversity', 'acousticEvenness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE ALL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(audios):\n",
    "    return pd.DataFrame({file: pd.concat([\n",
    "            getMFCC(audios[file]),\n",
    "            getSpectralEnergy(audios[file]),\n",
    "            computeParselMouthStats(audios[file]),\n",
    "            computeMath(audios[file]),\n",
    "            computSNR(audios[file]),\n",
    "            computeTemporalMedia(audios[file]),\n",
    "            computeAllFeatures(audios[file]),\n",
    "            computePeakFrequency(audios[file]),\n",
    "            computeEntropy(audios[file]),   \n",
    "            ], axis=0)\n",
    "        for file in audios}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.concat([computeMetrics(audioDevelopment), \n",
    "                    csvTotale.set_index('path')[['hnr', 'shimmer', 'jitter', 'gender', 'max_pitch', 'mean_pitch', 'min_pitch']]], axis=1)\n",
    "\n",
    "metrics['hnr']= metrics['hnr'].map(lambda x: 10*log10(np.abs(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VAL SCORE AND IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(HistGradientBoostingRegressor(), metrics,\n",
    "                 csvTotale['age'], cv=15, scoring='neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, imp in sorted(zip(list(metrics.columns)+['age'], \n",
    "                            pd.concat([metrics, csvTotale.set_index(csvTotale['path'])['age']], axis=1).corr('spearman')['age']), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f'{item}: {imp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ AUDIO EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioEval = {file: librosa.load('./data/audios_evaluation/'+file, sr=22050)[0] for file in csvEval['path']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE STATS AND REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsEval = pd.concat([computeMetrics(audioEval), \n",
    "                    csvEval.set_index('path')[['hnr', 'shimmer', 'jitter', 'gender', 'max_pitch', 'mean_pitch', 'min_pitch']]], axis=1)\n",
    "metricsEval['hnr']= metricsEval['hnr'].map(lambda x: 20*log10(np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(HistGradientBoostingRegressor(warm_start=True).fit(metrics, csvTotale['age']).predict(metricsEval),\n",
    "          name='Predicted',\n",
    "          index=csvEval.index).to_csv('finalPredict.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-cross_val_score(RandomForestRegressor(n_jobs=-1), metrics, csvTotale['age'], cv=15, scoring='neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-cross_val_score(make_pipeline(StandardScaler(), MLPRegressor(max_iter=int(1e4))), metrics, csvTotale['age'], cv=15, scoring='neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-cross_val_score(make_pipeline(StandardScaler(), SVR()), metrics, csvTotale['age'], cv=15, scoring='neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.zeros(csvEval.shape[0])+\n",
    "          (csvTotale['age'].mean()+csvTotale['age'].median())/2,  \n",
    "          name='Predicted').to_csv('Naive-Baseline.csv', header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = list(\n",
    "    map(lambda x: [x, -cross_val_score(DecisionTreeRegressor(**x), metrics, csvTotale['age'], \n",
    "                                       cv=15, scoring='neg_root_mean_squared_error').mean()],\n",
    "        ParameterGrid({\n",
    "            'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_depth': [10, 20, 30, None]\n",
    "        })\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(DecisionTreeRegressor(**(sorted(lista, key=lambda x: x[1])[0][0]))\n",
    "          .fit(metrics, csvTotale['age'])\n",
    "          .predict(metricsEval),\n",
    "          name='Predicted').to_csv('Tree-Baseline.csv', header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempScaler = StandardScaler()\n",
    "\n",
    "pd.Series((SVR().fit(tempScaler.fit_transform(metrics), csvTotale['age']).predict(tempScaler.transform(metricsEval)) +\n",
    "          RandomForestRegressor(n_jobs=-1).fit(metrics, csvTotale['age']).predict(metricsEval))/2,\n",
    "            name='Predicted').to_csv('Ensemble.csv', header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-(cross_val_score(make_pipeline(StandardScaler(), SVR()), metrics, csvTotale['age'], cv=15, scoring='neg_root_mean_squared_error').mean()+\n",
    "cross_val_score(RandomForestRegressor(n_jobs=-1), metrics, csvTotale['age'], cv=15, scoring='neg_root_mean_squared_error').mean())/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'loss':['squared_error', 'absolute_error', 'poisson', 'quantile'],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_leaf_nodes': [31, 63, 127],\n",
    "    'min_samples_leaf': [20, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=HistGradientBoostingRegressor(), param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(metrics, csvTotale['age'])\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best RMSE score: \", -grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
