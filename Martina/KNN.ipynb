{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a11ec9e",
   "metadata": {},
   "source": [
    "# Librerie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import sys\n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,      # Accuracy = (TP + TN) / (TP + TN + FP + FN) → percentuale predizioni corrette\n",
    "    precision_score,     # Precision = TP / (TP + FP) → quanti dei positivi predetti sono corretti\n",
    "    recall_score,        # Recall = TP / (TP + FN) → quanti veri positivi sono stati trovati\n",
    "    confusion_matrix,    # Matrice con: TP = veri positivi, FP = falsi positivi, FN = falsi negativi, TN = veri negativi\n",
    "    f1_score             # F1 = 2 * (Precision * Recall) / (Precision + Recall) → misura che considera precision e recall\n",
    ")\n",
    "\n",
    "#Inserire nuova funzione \n",
    "sys.path.insert(1,'../Data') # per mette di caricare la funzone \n",
    "from preprocessing import preprocessing_diabetes\n",
    "from preprocessing_v2 import preprocessing_diabetes_v2,combination_features\n",
    "from preprocessing_v3 import preprocessing_diabetes_v3,combination_features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61051f12",
   "metadata": {},
   "source": [
    "# Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modello \n",
    "# Descrizione pricipali parametri KNeighborsClassifier() : \n",
    "\n",
    "# n_neighbors: num vicini per classificazione.\n",
    "# weights: come pesare i vicini.\n",
    "# metric: tipo di distanza usata (es. 'euclidean' o 'manhattan').\n",
    "# algorithm: metodo usato per trovare i vicini (auto sceglie il migliore \n",
    "# in base ai dati passati attraverso fit). Vedere documentazione per varianti\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def knn_grid_search(X_train_in, y_train_in, max_neighbors=5, num_partizioni=5):\n",
    "    KNN = KNeighborsClassifier() \n",
    "\n",
    "    #Grid space\n",
    "\n",
    "    search_space = {\n",
    "    'n_neighbors': list(range(1, max_neighbors + 1)),  # ad esempio: [2, 3, 4, 5, k],\n",
    "    #'weights': ['uniform'],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    # 'uniform' = tutti i vicini hanno lo stesso peso nel voto\n",
    "    # 'distance' = i vicini più vicini hanno più peso (peso = 1 / distanza)\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "\n",
    "    #Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "    KNN,\n",
    "    param_grid = search_space,\n",
    "    scoring = { \"accuracy\": \"accuracy\",\n",
    "                \"precision\": \"precision\",\n",
    "                \"recall\": \"recall\",\n",
    "                \"f1\": \"f1\" },\n",
    "    \n",
    "    refit='f1', # metrica di valutazione\n",
    "    cv= num_partizioni,   # fold cross-validation  #NO CAPITO  VERBOSE\n",
    "    )\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    #COMMENTO \n",
    "    #Durante la Grid Search con cross-validation, per ogni combinazione di iperparametri\n",
    "    # vengono calcolate e salvate tutte le metriche specificate (accuracy, precision, recall, f1)\n",
    "    # su ciascuna fold della cross-validation. \n",
    "    # Il modello finale restituito è quello che massimizza la metrica indicata con 'refit' (f1),\n",
    "    # e viene rifittato su tutto il training set con i migliori iperparametri trovati.\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "   \n",
    "    \n",
    "    #Adattamento del modello ai dati di addestramento\n",
    "    grid_search.fit(X_train_in, y_train_in)\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    #COMMENTO \n",
    "    # I valori medi delle metriche calcolate durante la cross-validation sono salvati in cv_results_.\n",
    "     # Tuttavia, cv_results_ contiene i risultati per tutte le combinazioni di iperparametri testate.\n",
    "     # Per ottenere i valori medi delle metriche relativi al modello migliore \n",
    "     # bisogna usare l'indice grid_search.best_index_ così da accedere alla riga corretta.\n",
    "    #-----------------------------------------------------------------------------------------\n",
    " \n",
    "    # CREIAMO UN DATAFRAME CON LE PERFORMANCE DEL MODELLO MIGLIORE da visualizzare in output\n",
    "    best_index = grid_search.best_index_\n",
    "\n",
    "    # 1.Estraggo le medie delle metriche per il modello migliore\n",
    "    mean_accuracy = grid_search.cv_results_['mean_test_accuracy'][best_index]\n",
    "    mean_precision = grid_search.cv_results_['mean_test_precision'][best_index]\n",
    "    mean_recall = grid_search.cv_results_['mean_test_recall'][best_index]\n",
    "    mean_f1 = grid_search.cv_results_['mean_test_f1'][best_index]\n",
    "\n",
    "    # 2.Creo un DataFrame con le metriche medie della cross-validation per il modello migliore\n",
    "\n",
    "    cv_metrics_best_model_df = pd.DataFrame(\n",
    "        [[mean_accuracy, mean_precision, mean_recall, mean_f1]],\n",
    "        columns=['Accuracy', 'Precision', 'Recall', 'f1'],\n",
    "        index=['Performance Train']\n",
    "    )\n",
    "    #display(cv_metrics_best_model_df)\n",
    "\n",
    "    \n",
    "    KNN_Best= grid_search.best_estimator_    # modello con i migliori parametri, già fit\n",
    "    Parameter_Best = grid_search.best_params_    # dizionario con i migliori parametri trovati\n",
    "\n",
    "    \n",
    "    return KNN_Best, Parameter_Best , cv_metrics_best_model_df\n",
    "\n",
    "\n",
    "def evaluate_knn(knn_model, X_test, y_test, label='test'):\n",
    "    start=time.time()\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    end=time.time()\n",
    "    TempoEsecuzione = end - start\n",
    "    accuracy = accuracy_score(y_test, y_pred)      \n",
    "    precision = precision_score(y_test, y_pred)     \n",
    "    recall = recall_score(y_test, y_pred)           \n",
    "    f1 = f1_score(y_test, y_pred)                   \n",
    "    \n",
    "    # Creazione DataFrame performance \n",
    "    metrics_df = pd.DataFrame(\n",
    "    data=[[accuracy, precision, recall, f1, TempoEsecuzione]],   # Riga di valori calcolati\n",
    "    columns=['Accuracy', 'Precision', 'Recall', 'f1','Time'],  # Nomi delle colonne\n",
    "    index=[label]                               # Etichetta della riga, es. 'PCA', 'Classico', ecc.\n",
    "    )\n",
    "\n",
    "    conf_mat=confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(conf_mat,\n",
    "                        index=['Reali sani', 'Reali diabetici'],\n",
    "                        columns=['Predetti sani', 'Predetti diabetici']\n",
    "\n",
    "            )\n",
    "    return metrics_df, cm_df, \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134046a",
   "metadata": {},
   "source": [
    "# Importazione dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed1975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.read_csv('../Data/diabetes_train.csv')\n",
    "test_data= pd.read_csv('../Data/diabetes_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e93697",
   "metadata": {},
   "source": [
    "# Modelli con diversi preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20408357",
   "metadata": {},
   "source": [
    "### Preprocessing normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d45323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = preprocessing_diabetes(train_data, test_data) \n",
    "\n",
    "knn_best_norm, best_params_norm, performance_train_df_norm = knn_grid_search(X_train_norm, y_train_norm, max_neighbors=30, num_partizioni=10)\n",
    "display(performance_train_df_norm)  # visualizzazione delle performance del modello migliore\n",
    "\n",
    "# risultati GridSearchCV\n",
    "parameters_norm = pd.DataFrame([best_params_norm], index=[\"PARAMETERS BEST KNN\"])\n",
    "display(parameters_norm)\n",
    "\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_norm, conf_mat_norm = evaluate_knn(knn_best_norm, X_test_norm, y_test_norm, label='Performaramce Test')\n",
    "display(metrics_df_norm)\n",
    "\n",
    "# Visualizzazione della matrice di confusione\n",
    "display(conf_mat_norm)  # come dataframe\n",
    "sns.heatmap(conf_mat_norm, annot=True, fmt='d', cmap='Blues')  # visualizzazione con seaborn\n",
    "plt.title('Confusion Matrix norm')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf256c6",
   "metadata": {},
   "source": [
    "### Preprocessing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e173cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = preprocessing_diabetes(train_data, test_data, option='PCA') \n",
    "\n",
    "knn_best_PCA, best_params_PCA, performance_train_df_PCA = knn_grid_search(X_train_PCA, y_train_PCA, max_neighbors=30, num_partizioni=10)\n",
    "display(performance_train_df_PCA)  # visualizzazione delle performance del modello migliore\n",
    "\n",
    "# risultati GridSearchCV\n",
    "parameters_PCA = pd.DataFrame([best_params_PCA], index=[\"PARAMETERS BEST KNN\"])\n",
    "display(parameters_PCA)\n",
    "\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_PCA, conf_mat_PCA = evaluate_knn(knn_best_PCA, X_test_PCA, y_test_PCA, label='Performance Test')\n",
    "display(metrics_df_PCA)\n",
    "\n",
    "# Visualizzazione della matrice di confusione\n",
    "display(conf_mat_PCA)  # come dataframe\n",
    "sns.heatmap(conf_mat_PCA, annot=True, fmt='d', cmap='Blues')  # visualizzazione con seaborn\n",
    "plt.title('Confusion Matrix PCA')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1dec0e",
   "metadata": {},
   "source": [
    "### Preprocessing No Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0330ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Correlation\n",
    "\n",
    "X_train_noCorr, X_test_noCorr, y_train_noCorr, y_test_noCorr = preprocessing_diabetes(train_data, test_data, option='Delete') \n",
    "\n",
    "knn_best_noCorr, best_params_noCorr, performance_train_df_noCorr = knn_grid_search(X_train_noCorr, y_train_noCorr, max_neighbors=30, num_partizioni=10)\n",
    "display(performance_train_df_noCorr)  # visualizzazione delle performance del modello migliore\n",
    "\n",
    "# risultati GridSearchCV\n",
    "parameters_noCorr = pd.DataFrame([best_params_noCorr], index=[\"PARAMETERS BEST KNN\"])\n",
    "display(parameters_noCorr)\n",
    "\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_noCorr, conf_mat_noCorr = evaluate_knn(knn_best_noCorr, X_test_noCorr, y_test_noCorr, label='Performance Test')\n",
    "display(metrics_df_noCorr)\n",
    "\n",
    "# Visualizzazione della matrice di confusione\n",
    "display(conf_mat_noCorr)  # come dataframe\n",
    "sns.heatmap(conf_mat_noCorr, annot=True, fmt='d', cmap='Blues')  # visualizzazione con seaborn\n",
    "plt.title('Confusion Matrix noCorr')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3ff7b",
   "metadata": {},
   "source": [
    "### No Smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500273c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Smoking\n",
    "X_train_NoSmok, X_test_NoSmok, y_train_NoSmok, y_test_NoSmok = preprocessing_diabetes(train_data, test_data) \n",
    "\n",
    "#Togliamo l'attributo 'smoking'\n",
    "\n",
    "#Training set\n",
    "colonne_da_tenere = []\n",
    "for colonna in X_train_NoSmok.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere.append(colonna)\n",
    "        \n",
    "X_train_NoSmok = X_train_NoSmok[colonne_da_tenere]\n",
    "\n",
    "\n",
    "#Test set\n",
    "colonne_da_tenere_test = []\n",
    "for colonna in X_test_NoSmok.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere_test.append(colonna)\n",
    "\n",
    "X_test_NoSmok = X_test_NoSmok[colonne_da_tenere_test]\n",
    "\n",
    "\n",
    "# modello \n",
    "knn_best_NoSmok, best_params_NoSmok, performance_train_df_NoSmok = knn_grid_search(X_train_NoSmok, y_train_NoSmok, max_neighbors=30, num_partizioni=10)\n",
    "display(performance_train_df_NoSmok)  # visualizzazione delle performance del modello migliore\n",
    "\n",
    "# risultati GridSearchCV\n",
    "parameters_NoSmok = pd.DataFrame([best_params_NoSmok], index=[\"PARAMETERS BEST KNN\"])\n",
    "display(parameters_NoSmok)\n",
    "\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_NoSmok, conf_mat_NoSmok = evaluate_knn(knn_best_NoSmok, X_test_NoSmok, y_test_NoSmok, label='Performance Test')\n",
    "display(metrics_df_NoSmok)\n",
    "\n",
    "# Visualizzazione della matrice di confusione\n",
    "display(conf_mat_NoSmok)  # come dataframe\n",
    "sns.heatmap(conf_mat_NoSmok, annot=True, fmt='d', cmap='Blues')  # visualizzazione con seaborn\n",
    "plt.title('Confusion Matrix NoSmok')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c324946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERFORMANCE TRAINING\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TRAINING\n",
    "df_norm_test = performance_train_df_norm.reset_index(drop=True).copy()\n",
    "df_norm_test['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test = performance_train_df_PCA.reset_index(drop=True).copy()\n",
    "df_PCA_test['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test = performance_train_df_noCorr.reset_index(drop=True).copy()\n",
    "df_noCorr_test['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test = performance_train_df_NoSmok.reset_index(drop=True).copy()\n",
    "df_NoSmok_test['ModelName'] = 'No Smoking'\n",
    "\n",
    "#ìConcateniamo copie \n",
    "performance_train_all = pd.concat([df_norm_test, df_PCA_test, df_noCorr_test, df_NoSmok_test], ignore_index=True)\n",
    "\n",
    "\n",
    "performance_train_all = performance_train_all[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1']]\n",
    "pperformance_train_all = performance_train_all.set_index('ModelName')\n",
    "\n",
    "#display(performance_train_all)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#PARAMETRI MODELLO\n",
    "# Creiamo copie temporanee per confrontare i PARAMETRI dei modelli\n",
    "parameters_norm_cp = parameters_norm.reset_index(drop=True).copy()\n",
    "parameters_norm_cp['ModelName'] = 'Normal'\n",
    "\n",
    "parameters_PCA_cp = parameters_PCA.reset_index(drop=True).copy()\n",
    "parameters_PCA_cp['ModelName'] = 'PCA'\n",
    "\n",
    "parameters_noCorr_cp = parameters_noCorr.reset_index(drop=True).copy()\n",
    "parameters_noCorr_cp['ModelName'] = 'No Correlation'\n",
    "\n",
    "parameters_NoSmok_cp = parameters_NoSmok.reset_index(drop=True).copy()\n",
    "parameters_NoSmok_cp['ModelName'] = 'No Smoking'\n",
    "\n",
    "# Concatenazione \n",
    "parameters_all = pd.concat([parameters_norm_cp, parameters_PCA_cp, parameters_noCorr_cp, parameters_NoSmok_cp], ignore_index=True)\n",
    "\n",
    "parameters_all = parameters_all[['ModelName', 'metric', 'n_neighbors', 'weights']]\n",
    "parameters_all = parameters_all.set_index('ModelName')\n",
    "\n",
    "\n",
    "#display(parameters_all)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Unione delle performance e dei parametri\n",
    "\n",
    "#1. Riporto 'ModelName' da indice a colonna sui PARAMETRI per fare il merge \n",
    "parameters_all_reset = parameters_all.reset_index()\n",
    "\n",
    "# 2.Unisco performance e parametri usando 'ModelName' come chiave\n",
    "df_combined = performance_train_all.merge(parameters_all_reset, on='ModelName')\n",
    "\n",
    "display(df_combined)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PERFORMANCE TEST\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TEST\n",
    "df_norm_test = metrics_df_norm.reset_index(drop=True).copy()\n",
    "df_norm_test['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test = metrics_df_PCA.reset_index(drop=True).copy()\n",
    "df_PCA_test['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test = metrics_df_noCorr.reset_index(drop=True).copy()\n",
    "df_noCorr_test['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test = metrics_df_NoSmok.reset_index(drop=True).copy()\n",
    "df_NoSmok_test['ModelName'] = 'No Smoking'\n",
    "\n",
    "#Concateniamo\n",
    "performance_test_all = pd.concat([df_norm_test, df_PCA_test, df_noCorr_test, df_NoSmok_test], ignore_index=True)\n",
    "\n",
    "performance_test_all = performance_test_all[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1','Time']]\n",
    "performance_test_all = performance_test_all.set_index('ModelName')\n",
    "\n",
    "display(performance_test_all)\n",
    "\n",
    "# MATRICI DI CONFUSIONE\n",
    "\n",
    "conf_matrices = [conf_mat_norm, conf_mat_PCA, conf_mat_noCorr, conf_mat_NoSmok]\n",
    "titles = ['Normalized', 'PCA', 'No Correlation', 'No Smoking']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))  # (righe, colonne)\n",
    "\n",
    "\n",
    "sns.heatmap(conf_matrices[0], annot=True, fmt='d', cmap='Blues', ax=axes[0,0], annot_kws={\"size\": 21})\n",
    "axes[0,0].set_title(titles[0], fontsize=21)\n",
    "axes[0,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[0,0].set_ylabel('True label', fontsize=21)\n",
    "axes[0,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices[1], annot=True, fmt='d', cmap='Blues', ax=axes[0,1], annot_kws={\"size\": 21})\n",
    "axes[0,1].set_title(titles[1], fontsize=21)\n",
    "axes[0,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[0,1].set_ylabel('True label', fontsize=21)\n",
    "axes[0,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices[2], annot=True, fmt='d', cmap='Blues', ax=axes[1,0], annot_kws={\"size\": 21})\n",
    "axes[1,0].set_title(titles[2], fontsize=21)\n",
    "axes[1,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[1,0].set_ylabel('True label', fontsize=21)\n",
    "axes[1,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices[3], annot=True, fmt='d', cmap='Blues', ax=axes[1,1], annot_kws={\"size\": 21})\n",
    "axes[1,1].set_title(titles[3], fontsize=21)\n",
    "axes[1,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[1,1].set_ylabel('True label', fontsize=21)\n",
    "axes[1,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8dcaa",
   "metadata": {},
   "source": [
    "# PREPROCESSING 2 oversample=True,augment=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal\n",
    "X_train_norm2, X_test_norm2, y_train_norm2, y_test_norm2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True) \n",
    "knn_best_norm2, best_params_norm2, performance_train_df_norm2 = knn_grid_search(X_train_norm2, y_train_norm2, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_norm2 = pd.DataFrame([best_params_norm2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_norm2, conf_mat_norm2 = evaluate_knn(knn_best_norm2, X_test_norm2, y_test_norm2, label='Performaramce Test')\n",
    "\n",
    "# PCA\n",
    "X_train_PCA2, X_test_PCA2, y_train_PCA2, y_test_PCA2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True)\n",
    "knn_best_PCA2, best_params_PCA2, performance_train_df_PCA2 = knn_grid_search(X_train_PCA2, y_train_PCA2, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_PCA2 = pd.DataFrame([best_params_PCA2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_PCA2, conf_mat_PCA2 = evaluate_knn(knn_best_PCA2, X_test_PCA2, y_test_PCA2, label='Performance Test')\n",
    "\n",
    "#No Correlation\n",
    "X_train_noCorr2, X_test_noCorr2, y_train_noCorr2, y_test_noCorr2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True)\n",
    "knn_best_noCorr2, best_params_noCorr2, performance_train_df_noCorr2 = knn_grid_search(X_train_noCorr2, y_train_noCorr2, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_noCorr2 = pd.DataFrame([best_params_noCorr2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_noCorr2, conf_mat_noCorr2 = evaluate_knn(knn_best_noCorr2, X_test_noCorr2, y_test_noCorr2, label='Performance Test')\n",
    "\n",
    "#No Smoking\n",
    "X_train_NoSmok2, X_test_NoSmok2, y_train_NoSmok2, y_test_NoSmok2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True)\n",
    "#Togliamo l'attributo 'smoking'\n",
    "\n",
    "#Training set\n",
    "colonne_da_tenere2 = []\n",
    "for colonna in X_train_NoSmok2.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere2.append(colonna)\n",
    "        \n",
    "X_train_NoSmok2 = X_train_NoSmok2[colonne_da_tenere2]\n",
    "\n",
    "#Test set\n",
    "colonne_da_tenere_test2 = []\n",
    "for colonna in X_test_NoSmok2.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere_test2.append(colonna)\n",
    "\n",
    "X_test_NoSmok2 = X_test_NoSmok2[colonne_da_tenere_test2]\n",
    "# modello \n",
    "knn_best_NoSmok2, best_params_NoSmok2, performance_train_df_NoSmok2 = knn_grid_search(X_train_NoSmok2, y_train_NoSmok2, max_neighbors=30, num_partizioni=10)\n",
    "parameters_NoSmok2 = pd.DataFrame([best_params_NoSmok2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_NoSmok2, conf_mat_NoSmok2 = evaluate_knn(knn_best_NoSmok2, X_test_NoSmok2, y_test_NoSmok2, label='Performance Test')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#SECONDO PREPROCESSING\n",
    "#-----------------------------------------------------------------------------------------------------------stampa\n",
    "\n",
    "#PERFORMANCE TRAINING\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TRAINING\n",
    "df_norm_test2 = performance_train_df_norm2.reset_index(drop=True).copy()\n",
    "df_norm_test2['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test2 = performance_train_df_PCA2.reset_index(drop=True).copy()\n",
    "df_PCA_test2['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test2 = performance_train_df_noCorr2.reset_index(drop=True).copy()\n",
    "df_noCorr_test2['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test2 = performance_train_df_NoSmok2.reset_index(drop=True).copy()\n",
    "df_NoSmok_test2['ModelName'] = 'No Smoking'\n",
    "\n",
    "#ìConcateniamo copie \n",
    "performance_train_all2 = pd.concat([df_norm_test2, df_PCA_test2, df_noCorr_test2, df_NoSmok_test2], ignore_index=True)\n",
    "\n",
    "performance_train_all2 = performance_train_all2[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1']]\n",
    "performance_train_all2 = performance_train_all2.set_index('ModelName')\n",
    "\n",
    "#display(performance_train_all2)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#PARAMETRI MODELLO\n",
    "# Creiamo copie temporanee per confrontare i PARAMETRI dei modelli\n",
    "parameters_norm_cp2 = parameters_norm2.reset_index(drop=True).copy()\n",
    "parameters_norm_cp2['ModelName'] = 'Normal'\n",
    "\n",
    "parameters_PCA_cp2 = parameters_PCA2.reset_index(drop=True).copy()\n",
    "parameters_PCA_cp2['ModelName'] = 'PCA'\n",
    "\n",
    "parameters_noCorr_cp2 = parameters_noCorr2.reset_index(drop=True).copy()\n",
    "parameters_noCorr_cp2['ModelName'] = 'No Correlation'\n",
    "\n",
    "parameters_NoSmok_cp2 = parameters_NoSmok2.reset_index(drop=True).copy()\n",
    "parameters_NoSmok_cp2['ModelName'] = 'No Smoking'\n",
    "\n",
    "# Concatenazione \n",
    "parameters_all2 = pd.concat([parameters_norm_cp2, parameters_PCA_cp2, parameters_noCorr_cp2, parameters_NoSmok_cp2], ignore_index=True)\n",
    "\n",
    "parameters_all2 = parameters_all2[['ModelName', 'metric', 'n_neighbors', 'weights']]\n",
    "parameters_all2 = parameters_all2.set_index('ModelName')\n",
    "\n",
    "#display(parameters_all2)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Unione delle performance e dei parametri\n",
    "\n",
    "#1. Riporto 'ModelName' da indice a colonna sui PARAMETRI per fare il merge \n",
    "parameters_all_reset2 = parameters_all2.reset_index()\n",
    "\n",
    "# 2.Unisco performance e parametri usando 'ModelName' come chiave\n",
    "df_combined2 = performance_train_all2.merge(parameters_all_reset2, on='ModelName')\n",
    "\n",
    "display(df_combined2)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PERFORMANCE TEST\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TEST\n",
    "df_norm_test2 = metrics_df_norm2.reset_index(drop=True).copy()\n",
    "df_norm_test2['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test2 = metrics_df_PCA2.reset_index(drop=True).copy()\n",
    "df_PCA_test2['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test2 = metrics_df_noCorr2.reset_index(drop=True).copy()\n",
    "df_noCorr_test2['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test2 = metrics_df_NoSmok2.reset_index(drop=True).copy()\n",
    "df_NoSmok_test2['ModelName'] = 'No Smoking'\n",
    "\n",
    "#Concateniamo\n",
    "performance_test_all2 = pd.concat([df_norm_test2, df_PCA_test2, df_noCorr_test2, df_NoSmok_test2], ignore_index=True)\n",
    "\n",
    "performance_test_all2 = performance_test_all2[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1','Time']]\n",
    "performance_test_all2 = performance_test_all2.set_index('ModelName')\n",
    "\n",
    "display(performance_test_all2)\n",
    "\n",
    "# MATRICI DI CONFUSIONE\n",
    "\n",
    "conf_matrices2 = [conf_mat_norm2, conf_mat_PCA2, conf_mat_noCorr2, conf_mat_NoSmok2]\n",
    "titles2 = ['Normalized', 'PCA', 'No Correlation', 'No Smoking']\n",
    "\n",
    "fig2, axes2 = plt.subplots(2, 2, figsize=(15, 15))  # (righe, colonne)\n",
    "\n",
    "sns.heatmap(conf_matrices2[0], annot=True, fmt='d', cmap='Blues', ax=axes2[0,0], annot_kws={\"size\": 21})\n",
    "axes2[0,0].set_title(titles2[0], fontsize=21)\n",
    "axes2[0,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[0,0].set_ylabel('True label', fontsize=21)\n",
    "axes2[0,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices2[1], annot=True, fmt='d', cmap='Blues', ax=axes2[0,1], annot_kws={\"size\": 21})\n",
    "axes2[0,1].set_title(titles2[1], fontsize=21)\n",
    "axes2[0,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[0,1].set_ylabel('True label', fontsize=21)\n",
    "axes2[0,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices2[2], annot=True, fmt='d', cmap='Blues', ax=axes2[1,0], annot_kws={\"size\": 21})\n",
    "axes2[1,0].set_title(titles2[2], fontsize=21)\n",
    "axes2[1,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[1,0].set_ylabel('True label', fontsize=21)\n",
    "axes2[1,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices2[3], annot=True, fmt='d', cmap='Blues', ax=axes2[1,1], annot_kws={\"size\": 21})\n",
    "axes2[1,1].set_title(titles2[3], fontsize=21)\n",
    "axes2[1,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[1,1].set_ylabel('True label', fontsize=21)\n",
    "axes2[1,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8acf5",
   "metadata": {},
   "source": [
    "# PREPROCESSING 2 oversample=True,augment=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca94f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal\n",
    "X_train_norm3, X_test_norm3, y_train_norm3, y_test_norm3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False) \n",
    "knn_best_norm3, best_params_norm3, performance_train_df_norm3 = knn_grid_search(X_train_norm3, y_train_norm3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_norm3 = pd.DataFrame([best_params_norm3], index=[\"PARAMETERS BEST KNN\"])\n",
    "metrics_df_norm3, conf_mat_norm3 = evaluate_knn(knn_best_norm3, X_test_norm3, y_test_norm3, label='Performaramce Test')\n",
    "\n",
    "# PCA\n",
    "X_train_PCA3, X_test_PCA3, y_train_PCA3, y_test_PCA3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False)\n",
    "knn_best_PCA3, best_params_PCA3, performance_train_df_PCA3 = knn_grid_search(X_train_PCA3, y_train_PCA3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_PCA3 = pd.DataFrame([best_params_PCA3], index=[\"PARAMETERS BEST KNN\"])\n",
    "metrics_df_PCA3, conf_mat_PCA3 = evaluate_knn(knn_best_PCA3, X_test_PCA3, y_test_PCA3, label='Performance Test')\n",
    "\n",
    "#No Correlation\n",
    "X_train_noCorr3, X_test_noCorr3, y_train_noCorr3, y_test_noCorr3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False)\n",
    "knn_best_noCorr3, best_params_noCorr3, performance_train_df_noCorr3 = knn_grid_search(X_train_noCorr3, y_train_noCorr3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_noCorr3 = pd.DataFrame([best_params_noCorr3], index=[\"PARAMETERS BEST KNN\"])\n",
    "metrics_df_noCorr3, conf_mat_noCorr3 = evaluate_knn(knn_best_noCorr3, X_test_noCorr3, y_test_noCorr3, label='Performance Test')\n",
    "\n",
    "#No Smoking\n",
    "X_train_NoSmok3, X_test_NoSmok3, y_train_NoSmok3, y_test_NoSmok3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False)\n",
    "# Togliamo l'attributo 'smoking'\n",
    "\n",
    "#Training set\n",
    "colonne_da_tenere3 = []\n",
    "for colonna in X_train_NoSmok3.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere3.append(colonna)\n",
    "        \n",
    "X_train_NoSmok3 = X_train_NoSmok3[colonne_da_tenere3]\n",
    "\n",
    "#Test set\n",
    "colonne_da_tenere_test3 = []\n",
    "for colonna in X_test_NoSmok3.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere_test3.append(colonna)\n",
    "\n",
    "X_test_NoSmok3 = X_test_NoSmok3[colonne_da_tenere_test3]\n",
    "# modello \n",
    "knn_best_NoSmok3, best_params_NoSmok3, performance_train_df_NoSmok3 = knn_grid_search(X_train_NoSmok3, y_train_NoSmok3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_NoSmok3 = pd.DataFrame([best_params_NoSmok3], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_NoSmok3, conf_mat_NoSmok3 = evaluate_knn(knn_best_NoSmok3, X_test_NoSmok3, y_test_NoSmok3, label='PerformPerformance Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TERZO PREPROCESSING\n",
    "#-----------------------------------------------------------------------------------------------------------stampa\n",
    "\n",
    "#PERFORMANCE TRAINING\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TRAINING\n",
    "df_norm_test3 = performance_train_df_norm3.reset_index(drop=True).copy()\n",
    "df_norm_test3['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test3 = performance_train_df_PCA3.reset_index(drop=True).copy()\n",
    "df_PCA_test3['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test3 = performance_train_df_noCorr3.reset_index(drop=True).copy()\n",
    "df_noCorr_test3['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test3 = performance_train_df_NoSmok3.reset_index(drop=True).copy()\n",
    "df_NoSmok_test3['ModelName'] = 'No Smoking'\n",
    "\n",
    "#ìConcateniamo copie \n",
    "performance_train_all3 = pd.concat([df_norm_test3, df_PCA_test3, df_noCorr_test3, df_NoSmok_test3], ignore_index=True)\n",
    "\n",
    "performance_train_all3 = performance_train_all3[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1']]\n",
    "performance_train_all3 = performance_train_all3.set_index('ModelName')\n",
    "\n",
    "#display(performance_train_all3)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#PARAMETRI MODELLO\n",
    "# Creiamo copie temporanee per confrontare i PARAMETRI dei modelli\n",
    "parameters_norm_cp3 = parameters_norm3.reset_index(drop=True).copy()\n",
    "parameters_norm_cp3['ModelName'] = 'Normal'\n",
    "\n",
    "parameters_PCA_cp3 = parameters_PCA3.reset_index(drop=True).copy()\n",
    "parameters_PCA_cp3['ModelName'] = 'PCA'\n",
    "\n",
    "parameters_noCorr_cp3 = parameters_noCorr3.reset_index(drop=True).copy()\n",
    "parameters_noCorr_cp3['ModelName'] = 'No Correlation'\n",
    "\n",
    "parameters_NoSmok_cp3 = parameters_NoSmok3.reset_index(drop=True).copy()\n",
    "parameters_NoSmok_cp3['ModelName'] = 'No Smoking'\n",
    "\n",
    "# Concatenazione \n",
    "parameters_all3 = pd.concat([parameters_norm_cp3, parameters_PCA_cp3, parameters_noCorr_cp3, parameters_NoSmok_cp3], ignore_index=True)\n",
    "\n",
    "parameters_all3 = parameters_all3[['ModelName', 'metric', 'n_neighbors', 'weights']]\n",
    "parameters_all3 = parameters_all3.set_index('ModelName')\n",
    "\n",
    "#display(parameters_all3)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Unione delle performance e dei parametri\n",
    "\n",
    "#1. Riporto 'ModelName' da indice a colonna sui PARAMETRI per fare il merge \n",
    "parameters_all_reset3 = parameters_all3.reset_index()\n",
    "\n",
    "# 2.Unisco performance e parametri usando 'ModelName' come chiave\n",
    "df_combined3 = performance_train_all3.merge(parameters_all_reset3, on='ModelName')\n",
    "\n",
    "display(df_combined3)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PERFORMANCE TEST\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TEST\n",
    "df_norm_test3 = metrics_df_norm3.reset_index(drop=True).copy()\n",
    "df_norm_test3['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test3 = metrics_df_PCA3.reset_index(drop=True).copy()\n",
    "df_PCA_test3['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test3 = metrics_df_noCorr3.reset_index(drop=True).copy()\n",
    "df_noCorr_test3['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test3 = metrics_df_NoSmok3.reset_index(drop=True).copy()\n",
    "df_NoSmok_test3['ModelName'] = 'No Smoking'\n",
    "\n",
    "#Concateniamo\n",
    "performance_test_all3 = pd.concat([df_norm_test3, df_PCA_test3, df_noCorr_test3, df_NoSmok_test3], ignore_index=True)\n",
    "\n",
    "performance_test_all3 = performance_test_all3[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1','Time']]\n",
    "performance_test_all3 = performance_test_all3.set_index('ModelName')\n",
    "\n",
    "display(performance_test_all3)\n",
    "\n",
    "# MATRICI DI CONFUSIONE\n",
    "\n",
    "conf_matrices3 = [conf_mat_norm3, conf_mat_PCA3, conf_mat_noCorr3, conf_mat_NoSmok3]\n",
    "titles3 = ['Normalized', 'PCA', 'No Correlation', 'No Smoking']\n",
    "\n",
    "fig3, axes3 = plt.subplots(2, 2, figsize=(15, 15))  # (righe, colonne)\n",
    "\n",
    "sns.heatmap(conf_matrices3[0], annot=True, fmt='d', cmap='Blues', ax=axes3[0,0], annot_kws={\"size\": 21})\n",
    "axes3[0,0].set_title(titles3[0], fontsize=21)\n",
    "axes3[0,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[0,0].set_ylabel('True label', fontsize=21)\n",
    "axes3[0,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices3[1], annot=True, fmt='d', cmap='Blues', ax=axes3[0,1], annot_kws={\"size\": 21})\n",
    "axes3[0,1].set_title(titles3[1], fontsize=21)\n",
    "axes3[0,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[0,1].set_ylabel('True label', fontsize=21)\n",
    "axes3[0,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices3[2], annot=True, fmt='d', cmap='Blues', ax=axes3[1,0], annot_kws={\"size\": 21})\n",
    "axes3[1,0].set_title(titles3[2], fontsize=21)\n",
    "axes3[1,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[1,0].set_ylabel('True label', fontsize=21)\n",
    "axes3[1,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices3[3], annot=True, fmt='d', cmap='Blues', ax=axes3[1,1], annot_kws={\"size\": 21})\n",
    "axes3[1,1].set_title(titles3[3], fontsize=21)\n",
    "axes3[1,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[1,1].set_ylabel('True label', fontsize=21)\n",
    "axes3[1,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eee0dd",
   "metadata": {},
   "source": [
    "# PREPROCESSING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77123911",
   "metadata": {},
   "source": [
    "### first four \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal \n",
    "\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = preprocessing_diabetes(train_data, test_data) \n",
    "knn_best_norm, best_params_norm, performance_train_df_norm = knn_grid_search(X_train_norm, y_train_norm, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_norm = pd.DataFrame([best_params_norm], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_norm, conf_mat_norm = evaluate_knn(knn_best_norm, X_test_norm, y_test_norm, label='Performaramce Test')\n",
    "\n",
    "#_________________________________________________________________________________________________________________________________\n",
    "\n",
    "# PCA\n",
    "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = preprocessing_diabetes(train_data, test_data, option='PCA') \n",
    "knn_best_PCA, best_params_PCA, performance_train_df_PCA = knn_grid_search(X_train_PCA, y_train_PCA, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_PCA = pd.DataFrame([best_params_PCA], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_PCA, conf_mat_PCA = evaluate_knn(knn_best_PCA, X_test_PCA, y_test_PCA, label='Performance Test')\n",
    "\n",
    "#_________________________________________________________________________________________________________________________________\n",
    "\n",
    "#No Correlation\n",
    "X_train_noCorr, X_test_noCorr, y_train_noCorr, y_test_noCorr = preprocessing_diabetes(train_data, test_data, option='Delete') \n",
    "knn_best_noCorr, best_params_noCorr, performance_train_df_noCorr = knn_grid_search(X_train_noCorr, y_train_noCorr, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_noCorr = pd.DataFrame([best_params_noCorr], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_noCorr, conf_mat_noCorr = evaluate_knn(knn_best_noCorr, X_test_noCorr, y_test_noCorr, label='Performance Test')\n",
    "\n",
    "\n",
    "#_________________________________________________________________________________________________________________________________\n",
    "\n",
    "#No Smoking\n",
    "X_train_NoSmok, X_test_NoSmok, y_train_NoSmok, y_test_NoSmok = preprocessing_diabetes(train_data, test_data) \n",
    "knn_best_NoSmok, best_params_NoSmok, performance_train_df_NoSmok = knn_grid_search(X_train_NoSmok, y_train_NoSmok, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_NoSmok = pd.DataFrame([best_params_NoSmok], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_NoSmok, conf_mat_NoSmok = evaluate_knn(knn_best_NoSmok, X_test_NoSmok, y_test_NoSmok, label='Performance Test')\n",
    "\n",
    "#_________________________________________________________________________________________________________________________________\n",
    "\n",
    "#PERFORMANCE TRAINING\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TRAINING\n",
    "df_norm_test = performance_train_df_norm.reset_index(drop=True).copy()\n",
    "df_norm_test['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test = performance_train_df_PCA.reset_index(drop=True).copy()\n",
    "df_PCA_test['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test = performance_train_df_noCorr.reset_index(drop=True).copy()\n",
    "df_noCorr_test['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test = performance_train_df_NoSmok.reset_index(drop=True).copy()\n",
    "df_NoSmok_test['ModelName'] = 'No Smoking'\n",
    "\n",
    "#ìConcateniamo copie \n",
    "performance_train_all = pd.concat([df_norm_test, df_PCA_test, df_noCorr_test, df_NoSmok_test], ignore_index=True)\n",
    "\n",
    "\n",
    "performance_train_all = performance_train_all[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1']]\n",
    "pperformance_train_all = performance_train_all.set_index('ModelName')\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#PARAMETRI MODELLO\n",
    "# Creiamo copie temporanee per confrontare i PARAMETRI dei modelli\n",
    "parameters_norm_cp = parameters_norm.reset_index(drop=True).copy()\n",
    "parameters_norm_cp['ModelName'] = 'Normal'\n",
    "\n",
    "parameters_PCA_cp = parameters_PCA.reset_index(drop=True).copy()\n",
    "parameters_PCA_cp['ModelName'] = 'PCA'\n",
    "\n",
    "parameters_noCorr_cp = parameters_noCorr.reset_index(drop=True).copy()\n",
    "parameters_noCorr_cp['ModelName'] = 'No Correlation'\n",
    "\n",
    "parameters_NoSmok_cp = parameters_NoSmok.reset_index(drop=True).copy()\n",
    "parameters_NoSmok_cp['ModelName'] = 'No Smoking'\n",
    "\n",
    "# Concatenazione \n",
    "parameters_all = pd.concat([parameters_norm_cp, parameters_PCA_cp, parameters_noCorr_cp, parameters_NoSmok_cp], ignore_index=True)\n",
    "\n",
    "parameters_all = parameters_all[['ModelName', 'metric', 'n_neighbors', 'weights']]\n",
    "parameters_all = parameters_all.set_index('ModelName')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Unione delle performance e dei parametri\n",
    "\n",
    "#1. Riporto 'ModelName' da indice a colonna sui PARAMETRI per fare il merge \n",
    "parameters_all_reset = parameters_all.reset_index()\n",
    "\n",
    "# 2.Unisco performance e parametri usando 'ModelName' come chiave\n",
    "df_combined = performance_train_all.merge(parameters_all_reset, on='ModelName')\n",
    "\n",
    "display(df_combined)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PERFORMANCE TEST\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TEST\n",
    "df_norm_test = metrics_df_norm.reset_index(drop=True).copy()\n",
    "df_norm_test['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test = metrics_df_PCA.reset_index(drop=True).copy()\n",
    "df_PCA_test['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test = metrics_df_noCorr.reset_index(drop=True).copy()\n",
    "df_noCorr_test['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test = metrics_df_NoSmok.reset_index(drop=True).copy()\n",
    "df_NoSmok_test['ModelName'] = 'No Smoking'\n",
    "\n",
    "#Concateniamo\n",
    "performance_test_all = pd.concat([df_norm_test, df_PCA_test, df_noCorr_test, df_NoSmok_test], ignore_index=True)\n",
    "\n",
    "performance_test_all = performance_test_all[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1','Time']]\n",
    "performance_test_all = performance_test_all.set_index('ModelName')\n",
    "\n",
    "display(performance_test_all)\n",
    "\n",
    "# MATRICI DI CONFUSIONE\n",
    "\n",
    "conf_matrices = [conf_mat_norm, conf_mat_PCA, conf_mat_noCorr, conf_mat_NoSmok]\n",
    "titles = ['Normalized', 'PCA', 'No Correlation', 'No Smoking']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))  # (righe, colonne)\n",
    "\n",
    "\n",
    "sns.heatmap(conf_matrices[0], annot=True, fmt='d', cmap='Blues', ax=axes[0,0], annot_kws={\"size\": 21})\n",
    "axes[0,0].set_title(titles[0], fontsize=21)\n",
    "axes[0,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[0,0].set_ylabel('True label', fontsize=21)\n",
    "axes[0,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices[1], annot=True, fmt='d', cmap='Blues', ax=axes[0,1], annot_kws={\"size\": 21})\n",
    "axes[0,1].set_title(titles[1], fontsize=21)\n",
    "axes[0,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[0,1].set_ylabel('True label', fontsize=21)\n",
    "axes[0,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices[2], annot=True, fmt='d', cmap='Blues', ax=axes[1,0], annot_kws={\"size\": 21})\n",
    "axes[1,0].set_title(titles[2], fontsize=21)\n",
    "axes[1,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[1,0].set_ylabel('True label', fontsize=21)\n",
    "axes[1,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices[3], annot=True, fmt='d', cmap='Blues', ax=axes[1,1], annot_kws={\"size\": 21})\n",
    "axes[1,1].set_title(titles[3], fontsize=21)\n",
    "axes[1,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes[1,1].set_ylabel('True label', fontsize=21)\n",
    "axes[1,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3209a3",
   "metadata": {},
   "source": [
    "### oversample=True augment=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125727ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal\n",
    "X_train_norm2, X_test_norm2, y_train_norm2, y_test_norm2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True) \n",
    "knn_best_norm2, best_params_norm2, performance_train_df_norm2 = knn_grid_search(X_train_norm2, y_train_norm2, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_norm2 = pd.DataFrame([best_params_norm2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_norm2, conf_mat_norm2 = evaluate_knn(knn_best_norm2, X_test_norm2, y_test_norm2, label='Performaramce Test')\n",
    "\n",
    "# PCA\n",
    "X_train_PCA2, X_test_PCA2, y_train_PCA2, y_test_PCA2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True)\n",
    "knn_best_PCA2, best_params_PCA2, performance_train_df_PCA2 = knn_grid_search(X_train_PCA2, y_train_PCA2, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_PCA2 = pd.DataFrame([best_params_PCA2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_PCA2, conf_mat_PCA2 = evaluate_knn(knn_best_PCA2, X_test_PCA2, y_test_PCA2, label='Performance Test')\n",
    "\n",
    "#No Correlation\n",
    "X_train_noCorr2, X_test_noCorr2, y_train_noCorr2, y_test_noCorr2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True)\n",
    "knn_best_noCorr2, best_params_noCorr2, performance_train_df_noCorr2 = knn_grid_search(X_train_noCorr2, y_train_noCorr2, max_neighbors=30, num_partizioni=10)\n",
    "# risultati GridSearchCV\n",
    "parameters_noCorr2 = pd.DataFrame([best_params_noCorr2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_noCorr2, conf_mat_noCorr2 = evaluate_knn(knn_best_noCorr2, X_test_noCorr2, y_test_noCorr2, label='Performance Test')\n",
    "\n",
    "#No Smoking\n",
    "X_train_NoSmok2, X_test_NoSmok2, y_train_NoSmok2, y_test_NoSmok2 = preprocessing_diabetes_v2(train_data, test_data,oversample=True,augment=True)\n",
    "#Togliamo l'attributo 'smoking'\n",
    "\n",
    "#Training set\n",
    "colonne_da_tenere2 = []\n",
    "for colonna in X_train_NoSmok2.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere2.append(colonna)\n",
    "        \n",
    "X_train_NoSmok2 = X_train_NoSmok2[colonne_da_tenere2]\n",
    "\n",
    "#Test set\n",
    "colonne_da_tenere_test2 = []\n",
    "for colonna in X_test_NoSmok2.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere_test2.append(colonna)\n",
    "\n",
    "X_test_NoSmok2 = X_test_NoSmok2[colonne_da_tenere_test2]\n",
    "# modello \n",
    "knn_best_NoSmok2, best_params_NoSmok2, performance_train_df_NoSmok2 = knn_grid_search(X_train_NoSmok2, y_train_NoSmok2, max_neighbors=30, num_partizioni=10)\n",
    "parameters_NoSmok2 = pd.DataFrame([best_params_NoSmok2], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_NoSmok2, conf_mat_NoSmok2 = evaluate_knn(knn_best_NoSmok2, X_test_NoSmok2, y_test_NoSmok2, label='Performance Test')\n",
    "\n",
    "#SECONDO PREPROCESSING\n",
    "#-----------------------------------------------------------------------------------------------------------stampa\n",
    "\n",
    "#PERFORMANCE TRAINING\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TRAINING\n",
    "df_norm_test2 = performance_train_df_norm2.reset_index(drop=True).copy()\n",
    "df_norm_test2['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test2 = performance_train_df_PCA2.reset_index(drop=True).copy()\n",
    "df_PCA_test2['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test2 = performance_train_df_noCorr2.reset_index(drop=True).copy()\n",
    "df_noCorr_test2['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test2 = performance_train_df_NoSmok2.reset_index(drop=True).copy()\n",
    "df_NoSmok_test2['ModelName'] = 'No Smoking'\n",
    "\n",
    "#ìConcateniamo copie \n",
    "performance_train_all2 = pd.concat([df_norm_test2, df_PCA_test2, df_noCorr_test2, df_NoSmok_test2], ignore_index=True)\n",
    "\n",
    "performance_train_all2 = performance_train_all2[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1']]\n",
    "performance_train_all2 = performance_train_all2.set_index('ModelName')\n",
    "\n",
    "#display(performance_train_all2)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#PARAMETRI MODELLO\n",
    "# Creiamo copie temporanee per confrontare i PARAMETRI dei modelli\n",
    "parameters_norm_cp2 = parameters_norm2.reset_index(drop=True).copy()\n",
    "parameters_norm_cp2['ModelName'] = 'Normal'\n",
    "\n",
    "parameters_PCA_cp2 = parameters_PCA2.reset_index(drop=True).copy()\n",
    "parameters_PCA_cp2['ModelName'] = 'PCA'\n",
    "\n",
    "parameters_noCorr_cp2 = parameters_noCorr2.reset_index(drop=True).copy()\n",
    "parameters_noCorr_cp2['ModelName'] = 'No Correlation'\n",
    "\n",
    "parameters_NoSmok_cp2 = parameters_NoSmok2.reset_index(drop=True).copy()\n",
    "parameters_NoSmok_cp2['ModelName'] = 'No Smoking'\n",
    "\n",
    "# Concatenazione \n",
    "parameters_all2 = pd.concat([parameters_norm_cp2, parameters_PCA_cp2, parameters_noCorr_cp2, parameters_NoSmok_cp2], ignore_index=True)\n",
    "\n",
    "parameters_all2 = parameters_all2[['ModelName', 'metric', 'n_neighbors', 'weights']]\n",
    "parameters_all2 = parameters_all2.set_index('ModelName')\n",
    "\n",
    "#display(parameters_all2)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Unione delle performance e dei parametri\n",
    "\n",
    "#1. Riporto 'ModelName' da indice a colonna sui PARAMETRI per fare il merge \n",
    "parameters_all_reset2 = parameters_all2.reset_index()\n",
    "\n",
    "# 2.Unisco performance e parametri usando 'ModelName' come chiave\n",
    "df_combined2 = performance_train_all2.merge(parameters_all_reset2, on='ModelName')\n",
    "\n",
    "display(df_combined2)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PERFORMANCE TEST\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TEST\n",
    "df_norm_test2 = metrics_df_norm2.reset_index(drop=True).copy()\n",
    "df_norm_test2['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test2 = metrics_df_PCA2.reset_index(drop=True).copy()\n",
    "df_PCA_test2['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test2 = metrics_df_noCorr2.reset_index(drop=True).copy()\n",
    "df_noCorr_test2['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test2 = metrics_df_NoSmok2.reset_index(drop=True).copy()\n",
    "df_NoSmok_test2['ModelName'] = 'No Smoking'\n",
    "\n",
    "#Concateniamo\n",
    "performance_test_all2 = pd.concat([df_norm_test2, df_PCA_test2, df_noCorr_test2, df_NoSmok_test2], ignore_index=True)\n",
    "\n",
    "performance_test_all2 = performance_test_all2[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1','Time']]\n",
    "performance_test_all2 = performance_test_all2.set_index('ModelName')\n",
    "\n",
    "display(performance_test_all2)\n",
    "\n",
    "# MATRICI DI CONFUSIONE\n",
    "\n",
    "conf_matrices2 = [conf_mat_norm2, conf_mat_PCA2, conf_mat_noCorr2, conf_mat_NoSmok2]\n",
    "titles2 = ['Normalized', 'PCA', 'No Correlation', 'No Smoking']\n",
    "\n",
    "fig2, axes2 = plt.subplots(2, 2, figsize=(15, 15))  # (righe, colonne)\n",
    "\n",
    "sns.heatmap(conf_matrices2[0], annot=True, fmt='d', cmap='Blues', ax=axes2[0,0], annot_kws={\"size\": 21})\n",
    "axes2[0,0].set_title(titles2[0], fontsize=21)\n",
    "axes2[0,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[0,0].set_ylabel('True label', fontsize=21)\n",
    "axes2[0,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices2[1], annot=True, fmt='d', cmap='Blues', ax=axes2[0,1], annot_kws={\"size\": 21})\n",
    "axes2[0,1].set_title(titles2[1], fontsize=21)\n",
    "axes2[0,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[0,1].set_ylabel('True label', fontsize=21)\n",
    "axes2[0,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices2[2], annot=True, fmt='d', cmap='Blues', ax=axes2[1,0], annot_kws={\"size\": 21})\n",
    "axes2[1,0].set_title(titles2[2], fontsize=21)\n",
    "axes2[1,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[1,0].set_ylabel('True label', fontsize=21)\n",
    "axes2[1,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices2[3], annot=True, fmt='d', cmap='Blues', ax=axes2[1,1], annot_kws={\"size\": 21})\n",
    "axes2[1,1].set_title(titles2[3], fontsize=21)\n",
    "axes2[1,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes2[1,1].set_ylabel('True label', fontsize=21)\n",
    "axes2[1,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25d7cd",
   "metadata": {},
   "source": [
    "### oversample=True augment=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal\n",
    "X_train_norm3, X_test_norm3, y_train_norm3, y_test_norm3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False) \n",
    "knn_best_norm3, best_params_norm3, performance_train_df_norm3 = knn_grid_search(X_train_norm3, y_train_norm3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_norm3 = pd.DataFrame([best_params_norm3], index=[\"PARAMETERS BEST KNN\"])\n",
    "metrics_df_norm3, conf_mat_norm3 = evaluate_knn(knn_best_norm3, X_test_norm3, y_test_norm3, label='Performaramce Test')\n",
    "\n",
    "# PCA\n",
    "X_train_PCA3, X_test_PCA3, y_train_PCA3, y_test_PCA3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False)\n",
    "knn_best_PCA3, best_params_PCA3, performance_train_df_PCA3 = knn_grid_search(X_train_PCA3, y_train_PCA3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_PCA3 = pd.DataFrame([best_params_PCA3], index=[\"PARAMETERS BEST KNN\"])\n",
    "metrics_df_PCA3, conf_mat_PCA3 = evaluate_knn(knn_best_PCA3, X_test_PCA3, y_test_PCA3, label='Performance Test')\n",
    "\n",
    "#No Correlation\n",
    "X_train_noCorr3, X_test_noCorr3, y_train_noCorr3, y_test_noCorr3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False)\n",
    "knn_best_noCorr3, best_params_noCorr3, performance_train_df_noCorr3 = knn_grid_search(X_train_noCorr3, y_train_noCorr3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_noCorr3 = pd.DataFrame([best_params_noCorr3], index=[\"PARAMETERS BEST KNN\"])\n",
    "metrics_df_noCorr3, conf_mat_noCorr3 = evaluate_knn(knn_best_noCorr3, X_test_noCorr3, y_test_noCorr3, label='Performance Test')\n",
    "\n",
    "#No Smoking\n",
    "X_train_NoSmok3, X_test_NoSmok3, y_train_NoSmok3, y_test_NoSmok3 = preprocessing_diabetes_v2(train_data, test_data, oversample=True, augment=False)\n",
    "# Togliamo l'attributo 'smoking'\n",
    "\n",
    "#Training set\n",
    "colonne_da_tenere3 = []\n",
    "for colonna in X_train_NoSmok3.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere3.append(colonna)\n",
    "        \n",
    "X_train_NoSmok3 = X_train_NoSmok3[colonne_da_tenere3]\n",
    "\n",
    "#Test set\n",
    "colonne_da_tenere_test3 = []\n",
    "for colonna in X_test_NoSmok3.columns:\n",
    "    if 'smoking' not in colonna:\n",
    "        colonne_da_tenere_test3.append(colonna)\n",
    "\n",
    "X_test_NoSmok3 = X_test_NoSmok3[colonne_da_tenere_test3]\n",
    "# modello \n",
    "knn_best_NoSmok3, best_params_NoSmok3, performance_train_df_NoSmok3 = knn_grid_search(X_train_NoSmok3, y_train_NoSmok3, max_neighbors=30, num_partizioni=10)\n",
    "parameters_NoSmok3 = pd.DataFrame([best_params_NoSmok3], index=[\"PARAMETERS BEST KNN\"])\n",
    "# Valutazione del modello sui dati di test\n",
    "metrics_df_NoSmok3, conf_mat_NoSmok3 = evaluate_knn(knn_best_NoSmok3, X_test_NoSmok3, y_test_NoSmok3, label='PerformPerformance Test')\n",
    "\n",
    "\n",
    "#TERZO PREPROCESSING\n",
    "#-----------------------------------------------------------------------------------------------------------stampa\n",
    "\n",
    "#PERFORMANCE TRAINING\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TRAINING\n",
    "df_norm_test3 = performance_train_df_norm3.reset_index(drop=True).copy()\n",
    "df_norm_test3['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test3 = performance_train_df_PCA3.reset_index(drop=True).copy()\n",
    "df_PCA_test3['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test3 = performance_train_df_noCorr3.reset_index(drop=True).copy()\n",
    "df_noCorr_test3['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test3 = performance_train_df_NoSmok3.reset_index(drop=True).copy()\n",
    "df_NoSmok_test3['ModelName'] = 'No Smoking'\n",
    "\n",
    "#ìConcateniamo copie \n",
    "performance_train_all3 = pd.concat([df_norm_test3, df_PCA_test3, df_noCorr_test3, df_NoSmok_test3], ignore_index=True)\n",
    "\n",
    "performance_train_all3 = performance_train_all3[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1']]\n",
    "performance_train_all3 = performance_train_all3.set_index('ModelName')\n",
    "\n",
    "#display(performance_train_all3)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#PARAMETRI MODELLO\n",
    "# Creiamo copie temporanee per confrontare i PARAMETRI dei modelli\n",
    "parameters_norm_cp3 = parameters_norm3.reset_index(drop=True).copy()\n",
    "parameters_norm_cp3['ModelName'] = 'Normal'\n",
    "\n",
    "parameters_PCA_cp3 = parameters_PCA3.reset_index(drop=True).copy()\n",
    "parameters_PCA_cp3['ModelName'] = 'PCA'\n",
    "\n",
    "parameters_noCorr_cp3 = parameters_noCorr3.reset_index(drop=True).copy()\n",
    "parameters_noCorr_cp3['ModelName'] = 'No Correlation'\n",
    "\n",
    "parameters_NoSmok_cp3 = parameters_NoSmok3.reset_index(drop=True).copy()\n",
    "parameters_NoSmok_cp3['ModelName'] = 'No Smoking'\n",
    "\n",
    "# Concatenazione \n",
    "parameters_all3 = pd.concat([parameters_norm_cp3, parameters_PCA_cp3, parameters_noCorr_cp3, parameters_NoSmok_cp3], ignore_index=True)\n",
    "\n",
    "parameters_all3 = parameters_all3[['ModelName', 'metric', 'n_neighbors', 'weights']]\n",
    "parameters_all3 = parameters_all3.set_index('ModelName')\n",
    "\n",
    "#display(parameters_all3)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# Unione delle performance e dei parametri\n",
    "\n",
    "#1. Riporto 'ModelName' da indice a colonna sui PARAMETRI per fare il merge \n",
    "parameters_all_reset3 = parameters_all3.reset_index()\n",
    "\n",
    "# 2.Unisco performance e parametri usando 'ModelName' come chiave\n",
    "df_combined3 = performance_train_all3.merge(parameters_all_reset3, on='ModelName')\n",
    "\n",
    "display(df_combined3)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PERFORMANCE TEST\n",
    "\n",
    "# Creiamo copie temporanee per il confronto delle metriche di TEST\n",
    "df_norm_test3 = metrics_df_norm3.reset_index(drop=True).copy()\n",
    "df_norm_test3['ModelName'] = 'Normal'\n",
    "\n",
    "df_PCA_test3 = metrics_df_PCA3.reset_index(drop=True).copy()\n",
    "df_PCA_test3['ModelName'] = 'PCA'\n",
    "\n",
    "df_noCorr_test3 = metrics_df_noCorr3.reset_index(drop=True).copy()\n",
    "df_noCorr_test3['ModelName'] = 'No Correlation'\n",
    "\n",
    "df_NoSmok_test3 = metrics_df_NoSmok3.reset_index(drop=True).copy()\n",
    "df_NoSmok_test3['ModelName'] = 'No Smoking'\n",
    "\n",
    "#Concateniamo\n",
    "performance_test_all3 = pd.concat([df_norm_test3, df_PCA_test3, df_noCorr_test3, df_NoSmok_test3], ignore_index=True)\n",
    "\n",
    "performance_test_all3 = performance_test_all3[['ModelName', 'Accuracy', 'Precision', 'Recall', 'f1','Time']]\n",
    "performance_test_all3 = performance_test_all3.set_index('ModelName')\n",
    "\n",
    "display(performance_test_all3)\n",
    "\n",
    "# MATRICI DI CONFUSIONE\n",
    "\n",
    "conf_matrices3 = [conf_mat_norm3, conf_mat_PCA3, conf_mat_noCorr3, conf_mat_NoSmok3]\n",
    "titles3 = ['Normalized', 'PCA', 'No Correlation', 'No Smoking']\n",
    "\n",
    "fig3, axes3 = plt.subplots(2, 2, figsize=(15, 15))  # (righe, colonne)\n",
    "\n",
    "sns.heatmap(conf_matrices3[0], annot=True, fmt='d', cmap='Blues', ax=axes3[0,0], annot_kws={\"size\": 21})\n",
    "axes3[0,0].set_title(titles3[0], fontsize=21)\n",
    "axes3[0,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[0,0].set_ylabel('True label', fontsize=21)\n",
    "axes3[0,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices3[1], annot=True, fmt='d', cmap='Blues', ax=axes3[0,1], annot_kws={\"size\": 21})\n",
    "axes3[0,1].set_title(titles3[1], fontsize=21)\n",
    "axes3[0,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[0,1].set_ylabel('True label', fontsize=21)\n",
    "axes3[0,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices3[2], annot=True, fmt='d', cmap='Blues', ax=axes3[1,0], annot_kws={\"size\": 21})\n",
    "axes3[1,0].set_title(titles3[2], fontsize=21)\n",
    "axes3[1,0].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[1,0].set_ylabel('True label', fontsize=21)\n",
    "axes3[1,0].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "sns.heatmap(conf_matrices3[3], annot=True, fmt='d', cmap='Blues', ax=axes3[1,1], annot_kws={\"size\": 21})\n",
    "axes3[1,1].set_title(titles3[3], fontsize=21)\n",
    "axes3[1,1].set_xlabel('Predicted label', fontsize=21)\n",
    "axes3[1,1].set_ylabel('True label', fontsize=21)\n",
    "axes3[1,1].tick_params(axis='both', labelsize=21)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
